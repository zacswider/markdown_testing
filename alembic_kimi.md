# Alembic Documentation Transcription

## Tutorial - Alembic 1.16.5 documentation

### Contents

-   [The Migration Environment](#the-migration-environment)
-   [Creating an Environment](#creating-an-environment)
-   [Editing the .ini File](#editing-the-ini-file)
    -   [Escaping Characters in ini files](#escaping-characters-in-ini-files)
-   [Using pyproject.toml for configuration](#using-pyproject-toml-for-configuration)
-   [Create a Migration Script](#create-a-migration-script)
-   [Running our First Migration](#running-our-first-migration)
-   [Running our Second Migration](#running-our-second-migration)
-   [Partial Revision Identifiers](#partial-revision-identifiers)
-   [Relative Migration Identifiers](#relative-migration-identifiers)
-   [Getting Information](#getting-information)
    -   [Viewing History Ranges](#viewing-history-ranges)
-   [Downgrading](#downgrading)
-   [Next Steps](#next-steps)

### Tutorial

Alembic provides for the creation, management, and invocation of *change management* scripts for a relational database, using SQLAlchemy as the underlying engine. This tutorial will provide a full introduction to the theory and usage of this tool.

To begin, make sure Alembic is installed; a common way to install within a local virtual environment is described at [Installation](front.html#installation). As illustrated in that chapter, it is useful to have Alembic installed in the **same module / Python path as that of the target project**, usually using a [Python virtual environment](https://docs.python.org/3/tutorial/venv.html), so that when the `alembic` command is run, the Python script which is invoked by `alembic`, namely your project's `env.py` script, will have access to your application's models. This is not strictly necessary, however is usually preferred.

The tutorial below assumes the `alembic` command line utility is present in the local path and when invoked, will have access to the same Python module environment as that of the target project.

#### The Migration Environment

Usage of Alembic starts with creation of the *Migration Environment*. This is a directory of scripts that is specific to a particular application. The migration environment is created just once, and is then maintained along with the application's source code itself. The environment is created using the `init` command of Alembic, and is then customizable to suit the specific needs of the application.

The structure of this environment, including some generated migration scripts, looks like:

yourproject/
    alembic.ini
    pyproject.toml
    alembic/
        env.py
        README
        script.py.mako
        versions/
            3512b954651e\_add\_account.py
            2b1ae634e5cd\_add\_order\_id.py
            3adcc9a56557\_rename\_username\_field.py

The directory includes these directories/files:

-   `alembic.ini` - this is Alembic's main configuration file which is generated by all templates. A detailed walkthrough of this file is later in the section [Editing the .ini File](#tutorial-alembic-ini).
    
-   `pyproject.toml` - most modern Python projects have a `pyproject.toml` file. Alembic may optionally store project related configuration in this file as well; to use a `pyproject.toml` configuration, see the section [Using pyproject.toml for configuration](#using-pep-621).
    
-   `yourproject` - this is the root of your application's source code, or some directory within it.
    
-   `alembic` - this directory lives within your application's source tree and is the home of the migration environment. It can be named anything, and a project that uses multiple databases may even have more than one.
    
-   `env.py` - This is a Python script that is run whenever the alembic migration tool is invoked. At the very least, it contains instructions to configure and generate a SQLAlchemy engine, procure a connection from that engine along with a transaction, and then invoke the migration engine, using the connection as a source of database connectivity.
    
    The `env.py` script is part of the generated environment so that the way migrations run is entirely customizable. The exact specifics of how to connect are here, as well as the specifics of how the migration environment are invoked. The script can be modified so that multiple engines can be operated upon, custom arguments can be passed into the migration environment, application-specific libraries and models can be loaded in and made available.
    
    Alembic includes a set of initialization templates which feature different varieties of `env.py` for different use cases.
    
-   `README` - included with the various environment templates, should have something informative.
    
-   `script.py.mako` - This is a [Mako](http://www.makotemplates.org) template file which is used to generate new migration scripts. Whatever is here is used to generate new files within `versions/`. This is scriptable so that the structure of each migration file can be controlled, including standard imports to be within each, as well as changes to the structure of the `upgrade()` and `downgrade()` functions. For example, the `multidb` environment allows for multiple functions to be generated using a naming scheme `upgrade_engine1()`, `upgrade_engine2()`.
    
-   `versions/` - This directory holds the individual version scripts. Users of other migration tools may notice that the files here don't use ascending integers, and instead use a partial GUID approach. In Alembic, the ordering of version scripts is relative to directives within the scripts themselves, and it is theoretically possible to "splice" version files in between others, allowing migration sequences from different branches to be merged, albeit carefully by hand.
    

#### Creating an Environment

With a basic understanding of what the environment is, we can create one using `alembic init`. This will create an environment using the "generic" template:

$ cd /path/to/yourproject
$ source /path/to/yourproject/.venv/bin/activate   # assuming a local virtualenv
$ alembic init alembic

Where above, the `init` command was called to generate a migrations directory called `alembic`:

Creating directory /path/to/yourproject/alembic...done
Creating directory /path/to/yourproject/alembic/versions...done
Generating /path/to/yourproject/alembic.ini...done
Generating /path/to/yourproject/alembic/env.py...done
Generating /path/to/yourproject/alembic/README...done
Generating /path/to/yourproject/alembic/script.py.mako...done
Please edit configuration/connection/logging settings in
'/path/to/yourproject/alembic.ini' before proceeding.

The above layout is produced using a layout template called `generic`. Alembic also includes other environment templates. These can be listed out using the `list_templates` command:

$ alembic list\_templates
Available templates:

generic - Generic single-database configuration.
pyproject - pep-621 compliant configuration that includes pyproject.toml
async - Generic single-database configuration with an async dbapi.
multidb - Rudimentary multi-database configuration.

Templates are used via the 'init' command, e.g.:

  alembic init --template generic ./scripts

Changed in version 1.16.0: A new `pyproject` template has been added. See the section [Using pyproject.toml for configuration](#using-pep-621) for background.

#### Editing the .ini File

Alembic placed a file `alembic.ini` into the current directory. Alembic looks in the current directory for this file when any other commands are run; to indicate an alternative location, the `--config` option may be used, or the `ALEMBIC_CONFIG` environment variable may be set.

Tip

The file generated with the `generic` configuration template contains all directives for both source code configuration as well as database configuration. When using the `pyproject` template, the source code configuration elements will instead be in a separate `pyproject.toml` file, described in the section [Using pyproject.toml for configuration](#using-pep-621).

The all-in-one .ini file created by `generic` is illustrated below:

\# A generic, single database configuration.

\[alembic\]
# path to migration scripts.
# this is typically a path given in POSIX (e.g. forward slashes)
# format, relative to the token %(here)s which refers to the location of this
# ini file
script\_location = %(here)s/alembic

# template used to generate migration file names; The default value is %%(rev)s\_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# file\_template = %%(year)d\_%%(month).2d\_%%(day).2d\_%%(hour).2d%%(minute).2d-%%(rev)s\_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend\_sys\_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
# Any required deps can installed by adding \`alembic\[tz\]\` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the
# "slug" field
# truncate\_slug\_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision\_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to <script\_location>/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# the special token \`%(here)s\` is available which indicates the absolute path
# to this configuration file.
#
# The path separator used here should be the separator specified by "version\_path\_separator" below.
# version\_locations = %(here)s/bar:%(here)s/bat:%(here)s/alembic/versions

# path\_separator (New in Alembic 1.16.0, supersedes version\_path\_separator);
# This indicates what character is used to
# split lists of file paths, including version\_locations and prepend\_sys\_path
# within configparser files such as alembic.ini.
#
# The default rendered in new alembic.ini files is "os", which uses os.pathsep
# to provide os-dependent path splitting.
#
# Note that in order to support legacy alembic.ini files, this default does NOT
# take place if path\_separator is not present in alembic.ini.  If this
# option is omitted entirely, fallback logic is as follows:
#
# 1. Parsing of the version\_locations option falls back to using the legacy
#    "version\_path\_separator" key, which if absent then falls back to the legacy
#    behavior of splitting on spaces and/or commas.
# 2. Parsing of the prepend\_sys\_path option falls back to the legacy
#    behavior of splitting on spaces, commas, or colons.
#
# Valid values for path\_separator are:
#
# path\_separator = :
# path\_separator = ;
# path\_separator = space
# path\_separator = newline
#
# Use os.pathsep. Default configuration used for new projects.
path\_separator = os

# set to 'true' to search source files recursively
# in each "version\_locations" directory
# new in Alembic version 1.10
# recursive\_version\_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output\_encoding = utf-8

# database URL.  This is consumed by the user-maintained env.py script only.
# other means of configuring database URLs may be customized within the env.py
# file.
# See notes in "escaping characters in ini files" for guidelines on
# passwords
sqlalchemy.url = driver://user:pass@localhost/dbname

# \[post\_write\_hooks\]
# This section defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console\_scripts runner,
# against the "black" entrypoint
# hooks = black
# black.type = console\_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION\_SCRIPT\_FILENAME

# lint with attempts to fix using "ruff" - use the module runner, against the "ruff" module
# hooks = ruff
# ruff.type = module
# ruff.module = ruff
# ruff.options = check --fix REVISION\_SCRIPT\_FILENAME

# Alternatively, use the exec runner to execute a binary found on your PATH
# hooks = ruff
# ruff.type = exec
# ruff.executable = ruff
# ruff.options = check --fix REVISION\_SCRIPT\_FILENAME

# Logging configuration.  This is also consumed by the user-maintained
# env.py script only.
\[loggers\]
keys = root,sqlalchemy,alembic

\[handlers\]
keys = console

\[formatters\]
keys = generic

\[logger\_root\]
level = WARNING
handlers = console
qualname =

\[logger\_sqlalchemy\]
level = WARNING
handlers =
qualname = sqlalchemy.engine

\[logger\_alembic\]
level = INFO
handlers =
qualname = alembic

\[handler\_console\]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

\[formatter\_generic\]
format = %(levelname)-5.5s \[%(name)s\] %(message)s
datefmt = %H:%M:%S

The `alembic.ini` file is consumed by Alembic using Python's [configparser.ConfigParser](https://docs.python.org/3/library/configparser.html#configparser.ConfigParser) library. The `%(here)s` variable is provided as a substitution which is populated with the absolute path to the `alembic.ini` file itself. This can be used to produce correct pathnames to directories and files relative to where the config file is located.

Tip

Percent signs in `alembic.ini` configuration variables that are not part of an interpolation token like `%(here)s`, including percent signs that are part of the SQLAlchemy database URL for its own URL-escaping requirements, must themselves be escaped. See the section [Escaping Characters in ini files](#escaping-percent-signs) for more information.

This file contains the following features:

-   `[alembic]` - this is the section read by Alembic to determine configuration. Alembic's core implementation does not directly read any other areas of the file, not including additional directives that may be consumed from the end-user-customizable `env.py` file (see note below). The name "alembic" (for configparser config only, not `pyproject.toml`) can be customized using the `--name` commandline flag; see [Run Multiple Alembic Environments from one .ini file](cookbook.html#multiple-environments) for a basic example of this.
    
    Note
    
    The default `env.py` file included with Alembic's environment templates will also read from the logging sections `[logging]`, `[handlers]` etc. If the configuration file in use does not contain logging directives, please remove the `fileConfig()` directive within the generated `env.py` file to prevent it from attempting to configure logging.
    
-   `script_location` - this is the location of the Alembic environment. It is normally specified as a filesystem location relative to the `%(here)s` token, which indicates where the config file itself is located. The location may also be a plain relative path, where it's interpreted as relative to the current directory, or an absolute path.
    
    This is the only key required by Alembic in all cases. The generation of the .ini file by the command `alembic init alembic` automatically placed the directory name `alembic` here. The special variable `%(here)s` can also be used, as in `%(here)s/alembic`.
    
    For support of applications that package themselves into .egg files, the value can also be specified as a [package resource](https://setuptools.readthedocs.io/en/latest/pkg_resources.html), in which case `resource_filename()` is used to find the file (new in 0.2.2). Any non-absolute URI which contains colons is interpreted here as a resource name, rather than a straight filename.
    
-   `file_template` - this is the naming scheme used to generate new migration files. Uncomment the presented value if you would like the migration files to be prepended with date and time, so that they are listed in chronological order. The default value is `%%(rev)s_%%(slug)s`. Tokens available include:
    
    > -   `%%(rev)s` - revision id
    >     
    > -   `%%(slug)s` - a truncated string derived from the revision message
    >     
    > -   `%%(epoch)s` - epoch timestamp based on the create date; this makes use of the Python `datetime.timestamp()` method to produce an epoch value.
    >     
    > -   `%%(year)d`, `%%(month).2d`, `%%(day).2d`, `%%(hour).2d`, `%%(minute).2d`, `%%(second).2d` - components of the create date, by default `datetime.datetime.now()` unless the `timezone` configuration option is also used.
    >     
    
-   `timezone` - an optional timezone name (e.g. `UTC`, `EST5EDT`, etc.) that will be applied to the timestamp which renders inside the migration file's comment as well as within the filename. This option requires Python>=3.9 or installing the `backports.zoneinfo` library and the `tzdata` library. If `timezone` is specified, the create date object is no longer derived from `datetime.datetime.now()` and is instead generated as:
    
    datetime.datetime.utcnow().replace(
      tzinfo\=datetime.timezone.utc
    ).astimezone(ZoneInfo(<timezone\>))
    
    Changed in version 1.13.0: Python standard library `zoneinfo` is now used for timezone rendering in migrations; previously `python-dateutil` was used.
    
-   `truncate_slug_length` - defaults to 40, the max number of characters to include in the "slug" field.
    
-   `sqlalchemy.url` - A URL to connect to the database via SQLAlchemy. This configuration value is only used if the `env.py` file calls upon them; in the "generic" template, the call to `config.get_main_option("sqlalchemy.url")` in the `run_migrations_offline()` function and the call to `engine_from_config(prefix="sqlalchemy.")` in the `run_migrations_online()` function are where this key is referenced. If the SQLAlchemy URL should come from some other source, such as from environment variables or a global registry, or if the migration environment makes use of multiple database URLs, the developer is encouraged to alter the `env.py` file to use whatever methods are appropriate in order to acquire the database URL or URLs.
    
-   `revision_environment` - this is a flag which when set to the value 'true', will indicate that the migration environment script `env.py` should be run unconditionally when generating new revision files, as well as when running the `alembic history` command.
    
-   `sourceless` - when set to 'true', revision files that only exist as .pyc or .pyo files in the versions directory will be used as versions, allowing "sourceless" versioning folders. When left at the default of 'false', only .py files are consumed as version files.
    
-   `version_locations` - an optional list of revision file locations, to allow revisions to exist in multiple directories simultaneously. See [Working with Multiple Bases](branches.html#multiple-bases) for examples.
    
-   `path_separator` - a separator character for the `version_locations` and `prepend_sys_path` path lists. Only applies to configparser config, not needed if `pyproject.toml` configuration is used. See [Working with Multiple Bases](branches.html#multiple-bases) for examples.
    
-   `recursive_version_locations` - when set to 'true', revision files are searched recursively in each "version\_locations" directory.
    
    Added in version 1.10.
    
-   `output_encoding` - the encoding to use when Alembic writes the `script.py.mako` file into a new migration file. Defaults to `'utf-8'`.
    
-   `[loggers]`, `[handlers]`, `[formatters]`, `[logger_*]`, `[handler_*]`, `[formatter_*]` - these sections are all part of Python's standard logging configuration, the mechanics of which are documented at [Configuration File Format](http://docs.python.org/library/logging.config.html#configuration-file-format). As is the case with the database connection, these directives are used directly as the result of the `logging.config.fileConfig()` call present in the `env.py` script, which you're free to modify.
    

For starting up with just a single database and the generic configuration, setting up the SQLAlchemy URL is all that's needed:

sqlalchemy.url \= postgresql://scott:tiger@localhost/test

##### Escaping Characters in ini files

As mentioned previously, Alembic's .ini file format uses Python [ConfigParser](https://docs.python.org/3/library/configparser.html#configparser.ConfigParser) to parse the file. `ConfigParser` 's [interpolation feature is enabled](https://docs.python.org/3/library/configparser.html#interpolation-of-values) in this operation to support the use of the `%(here)s` token, as well as any other tokens that are user-configurable via the [`Config.config_args`](api/config.html#alembic.config.Config.params.config_args "alembic.config.Config") parameter when creating a custom [`Config`](api/config.html#alembic.config.Config "alembic.config.Config") object.

This means that any literal string that includes a percent sign that is not part of an interpolated variable must be escaped by doubling it. That is, for a configuration value like this in a Python script:

my\_configuration\_value \= "some % string"

To be parsed from the .ini file would need to be placed as:

\[alembic\]

my\_configuration\_value \= some %% string

This escaping can be seen in the sample `alembic.ini` file, illustrated in such values as `file_template`:

\# template used to generate migration file names; The default value is %%(rev)s\_%%(slug)s
file\_template \= %%(year)d\_%%(month).2d\_%%(day).2d\_%%(hour).2d%%(minute).2d\-%%(rev)s\_%%(slug)s

Where above, the actual `file_template` that is sent to Alembic's file generation system would be `%(year)d_%(month).2d_%(day).2d_%(hour).2d%(minute).2d-%(rev)s_%(slug)s`.

Tip

Alembic also employs percent-sign interpolation of values when retrieving values from a `pyproject.toml` file, as documented at [Using pyproject.toml for configuration](#using-pep-621). So the same percent-doubling steps that apply to `alembic.ini` configuration variables also apply to `pyproject.toml`, even though database URLs are not configured in this file. This escaping can be seen in the sample `file_template` value above. See the section [Escaping Characters in ini files](#escaping-percent-signs) for background.

For the SQLAlchemy URL, percent signs are used to escape syntactically- significant characters such as the `@` sign as well as the percent sign itself. For a password such as `"P@ssw%rd"`:

\>>> my\_actual\_password \= "P@ssw%rd"

As [documented by SQLAlchemy](https://docs.sqlalchemy.org/core/engines.html#escaping-special-characters-such-as-signs-in-passwords), the `@` sign as well as the percent sign when placed into a URL should be escaped with `urllib.parse.quote_plus`:

\>>> import urllib.parse
\>>> sqlalchemy\_quoted\_password \= urllib.parse.quote\_plus(my\_actual\_password)
\>>> sqlalchemy\_quoted\_password
'P%40ssw%25rd'

This URL quoting can also be seen in SQLAlchemy's own stringification of URLs:

\>>> from sqlalchemy import URL
\>>> URL.create(
...   "some\_db", username\="scott", password\=my\_actual\_password, host\="host"
... ).render\_as\_string(hide\_password\=False)
'some\_db://scott:P%40ssw%25rd@host'

For the above escaped password string `'P%40ssw%rd'` to be placed into a `ConfigParser` file that includes interpolation of percent signs, `%` characters are doubled:

\>>> sqlalchemy\_quoted\_password.replace("%", "%%")
'P%%40ssw%%25rd'

Here's a complete program that will compose a URL and show the correct configparser form for a given set of database connection details, as well as illustrate how to assert these forms for correctness:

from sqlalchemy import URL, make\_url

database\_driver \= input("database driver? ")
username \= input("username? ")
password \= input("password? ")
host \= input("host? ")
port \= input("port? ")
database \= input("database? ")

sqlalchemy\_url \= URL.create(
    drivername\=database\_driver,
    username\=username,
    password\=password,
    host\=host,
    port\=int(port),
    database\=database,
)

stringified\_sqlalchemy\_url \= sqlalchemy\_url.render\_as\_string(
    hide\_password\=False
)

\# assert make\_url round trip
assert make\_url(stringified\_sqlalchemy\_url) \== sqlalchemy\_url

print(
    f"The correctly escaped string that can be passed "
    f"to SQLAlchemy make\_url() and create\_engine() is:"
    f"\\n\\n     {stringified\_sqlalchemy\_url!r}\\n"
)

percent\_replaced\_url \= stringified\_sqlalchemy\_url.replace("%", "%%")

\# assert percent-interpolated plus make\_url round trip
assert make\_url(percent\_replaced\_url % {}) \== sqlalchemy\_url

print(
    f"The SQLAlchemy URL that can be placed in a ConfigParser "
    f"file such as alembic.ini is:\\n\\n      "
    f"sqlalchemy.url = {percent\_replaced\_url}\\n"
)

The above program should eliminate any ambiguity when placing a SQLAlchemy URL into a configparser file:

$ python alembic\_pw\_script.py
database driver? postgresql+psycopg2
username? scott
password? P@ssw%rd
host? localhost
port? 5432
database? testdb
The correctly escaped string that can be passed to SQLAlchemy make\_url() and create\_engine() is:

    'postgresql+psycopg2://scott:P%40ssw%25rd@localhost:5432/testdb'

The SQLAlchemy URL that can be placed in a ConfigParser file such as alembic.ini is:

      sqlalchemy.url = postgresql+psycopg2://scott:P%%40ssw%%25rd@localhost:5432/testdb

#### Using pyproject.toml for configuration

Added in version 1.16.0.

As the `alembic.ini` file includes a subset of options that are specific to the organization and production of Python code within the local environment, these specific options may alternatively be placed in the application's `pyproject.toml` file, to allow for [**PEP 621**](https://peps.python.org/pep-0621/) compliant configuration.

Use of `pyproject.toml` does not preclude having an `alembic.ini` file as well, as `alembic.ini` is still the default location for **deployment** details such as database URLs, connectivity options, and logging to be present. However, as connectivity and logging is consumed only by user-managed code within the `env.py` file, it is feasible to have an environment that does not require the `alembic.ini` file itself to be present at all, if these configurational elements are consumed from other places elsewhere in the application. Alembic will still run successfully if only a `pyproject.toml` file is present and no `alembic.ini` is found.

To start with a pyproject configuration, the most straightforward approach is to use the `pyproject` template:

alembic init \--template pyproject alembic

The output states that the existing pyproject file is being augmented with additional directives:

Creating directory /path/to/yourproject/alembic...done
Creating directory /path/to/yourproject/alembic/versions...done
Appending to /path/to/yourproject/pyproject.toml...done
Generating /path/to/yourproject/alembic.ini...done
Generating /path/to/yourproject/alembic/env.py...done
Generating /path/to/yourproject/alembic/README...done
Generating /path/to/yourproject/alembic/script.py.mako...done
Please edit configuration/connection/logging settings in
'/path/to/yourproject/pyproject.toml' and
'/path/to/yourproject/alembic.ini' before proceeding.

Alembic's template runner will generate a new `pyproject.toml` file if one does not exist, or it will append directives to an existing `pyproject.toml` file that does not already include alembic directives.

Within the `pyproject.toml` file, the default section generated looks mostly like the `alembic.ini` file, with the welcome exception that lists of values are supported directly; this means the values `prepend_sys_path` and `version_locations` are specified as lists. The `%(here)s` token also remains available as the absolute path to the `pyproject.toml` file:

\[tool.alembic\]
\# path to migration scripts
script\_location \= "%(here)s/alembic"

\# template used to generate migration file names; The default value is %%(rev)s\_%%(slug)s
\# Uncomment the line below if you want the files to be prepended with date and time
\# file\_template = %%(year)d\_%%(month).2d\_%%(day).2d\_%%(hour).2d%%(minute).2d-%%(rev)s\_%%(slug)s

\# additional paths to be prepended to sys.path. defaults to the current working directory.
prepend\_sys\_path \= \[
    "."
\]

\# timezone to use when rendering the date within the migration file
\# as well as the filename.
\# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
\# Any required deps can installed by adding \`alembic\[tz\]\` to the pip requirements
\# string value is passed to ZoneInfo()
\# leave blank for localtime
\# timezone =

\# max length of characters to apply to the
\# "slug" field
\# truncate\_slug\_length = 40

\# set to 'true' to run the environment during
\# the 'revision' command, regardless of autogenerate
\# revision\_environment = false

\# set to 'true' to allow .pyc and .pyo files without
\# a source .py file to be detected as revisions in the
\# versions/ directory
\# sourceless = false

\# version location specification; This defaults
\# to <script\_location>/versions.  When using multiple version
\# directories, initial revisions must be specified with --version-path.
\# version\_locations = \[
\#    "%(here)s/alembic/versions",
\#    "%(here)s/foo/bar"
\# \]

\# set to 'true' to search source files recursively
\# in each "version\_locations" directory
\# new in Alembic version 1.10
\# recursive\_version\_locations = false

\# the output encoding used when revision files
\# are written from script.py.mako
\# output\_encoding = "utf-8"

\# This section defines scripts or Python functions that are run
\# on newly generated revision scripts.  See the documentation for further
\# detail and examples
\# \[\[tool.alembic.post\_write\_hooks\]\]
\# format using "black" - use the console\_scripts runner,
\# against the "black" entrypoint
\# name = "black"
\# type = "console\_scripts"
\# entrypoint = "black"
\# options = "-l 79 REVISION\_SCRIPT\_FILENAME"
#
\# \[\[tool.alembic.post\_write\_hooks\]\]
\# lint with attempts to fix using "ruff" - use the exec runner,
\# execute a binary
\# name = "ruff"
\# type = "exec"
\# executable = "%(here)s/.venv/bin/ruff"
\# options = "check --fix REVISION\_SCRIPT\_FILENAME"

Tip

As Alembic adds support for interpolation tokens like `%(here)s` to its handling of `pyproject.toml` values, the same percent-sign escaping steps that apply to `alembic.ini` configuration variables also apply to `pyproject.toml`, even though database URLs are not configured in this file. This escaping can be seen in the sample `file_template` value above. See the section [Escaping Characters in ini files](#escaping-percent-signs) for background.

The `alembic.ini` file for this template is truncated and contains only database configuration and logging configuration:

\[alembic\]

# database URL.  This is consumed by the user-maintained env.py script only.
# other means of configuring database URLs may be customized within the env.py
# file.
sqlalchemy.url = driver://user:pass@localhost/dbname

# Logging configuration.  This is also consumed by the user-maintained
# env.py script only.
\[loggers\]
keys = root,sqlalchemy,alembic

\[handlers\]
keys = console

\[formatters\]
keys = generic

\[logger\_root\]
level = WARNING
handlers = console
qualname =

\[logger\_sqlalchemy\]
level = WARNING
handlers =
qualname = sqlalchemy.engine

\[logger\_alembic\]
level = INFO
handlers =
qualname = alembic

\[handler\_console\]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

\[formatter\_generic\]
format = %(levelname)-5.5s \[%(name)s\] %(message)s
datefmt = %H:%M:%S

When `env.py` is configured to obtain database connectivity and logging configuration from places other than `alembic.ini`, the file can be omitted altogether.

#### Create a Migration Script

With the environment in place we can create a new revision, using `alembic revision`:

$ alembic revision -m "create account table"
Generating /path/to/yourproject/alembic/versions/1975ea83b712\_create\_accoun
t\_table.py...done

A new file `1975ea83b712_create_account_table.py` is generated. Looking inside the file:

"""create account table

Revision ID: 1975ea83b712
Revises:
Create Date: 2011-11-08 11:40:27.089406

"""

\# revision identifiers, used by Alembic.
revision \= '1975ea83b712'
down\_revision \= None
branch\_labels \= None

from alembic import op
import sqlalchemy as sa

def upgrade():
    pass

def downgrade():
    pass

The file contains some header information, identifiers for the current revision and a "downgrade" revision, an import of basic Alembic directives, and empty `upgrade()` and `downgrade()` functions. Our job here is to populate the `upgrade()` and `downgrade()` functions with directives that will apply a set of changes to our database. Typically, `upgrade()` is required while `downgrade()` is only needed if down-revision capability is desired, though it's probably a good idea.

Another thing to notice is the `down_revision` variable. This is how Alembic knows the correct order in which to apply migrations. When we create the next revision, the new file's `down_revision` identifier would point to this one:

\# revision identifiers, used by Alembic.
revision \= 'ae1027a6acf'
down\_revision \= '1975ea83b712'

Every time Alembic runs an operation against the `versions/` directory, it reads all the files in, and composes a list based on how the `down_revision` identifiers link together, with the `down_revision` of `None` representing the first file. In theory, if a migration environment had thousands of migrations, this could begin to add some latency to startup, but in practice a project should probably prune old migrations anyway (see the section [Building an Up to Date Database from Scratch](cookbook.html#building-uptodate) for a description on how to do this, while maintaining the ability to build the current database fully).

We can then add some directives to our script, suppose adding a new table `account`:

def upgrade():
    op.create\_table(
        'account',
        sa.Column('id', sa.Integer, primary\_key\=True),
        sa.Column('name', sa.String(50), nullable\=False),
        sa.Column('description', sa.Unicode(200)),
    )

def downgrade():
    op.drop\_table('account')

[`create_table()`](ops.html#alembic.operations.Operations.create_table "alembic.operations.Operations.create_table") and [`drop_table()`](ops.html#alembic.operations.Operations.drop_table "alembic.operations.Operations.drop_table") are Alembic directives. Alembic provides all the basic database migration operations via these directives, which are designed to be as simple and minimalistic as possible; there's no reliance upon existing table metadata for most of these directives. They draw upon a global "context" that indicates how to get at a database connection (if any; migrations can dump SQL/DDL directives to files as well) in order to invoke the command. This global context is set up, like everything else, in the `env.py` script.

An overview of all Alembic directives is at [Operation Reference](ops.html#ops).

#### Running our First Migration

We now want to run our migration. Assuming our database is totally clean, it's as yet unversioned. The `alembic upgrade` command will run upgrade operations, proceeding from the current database revision, in this example `None`, to the given target revision. We can specify `1975ea83b712` as the revision we'd like to upgrade to, but it's easier in most cases just to tell it "the most recent", in this case `head`:

$ alembic upgrade head
INFO  \[alembic.context\] Context class PostgresqlContext.
INFO  \[alembic.context\] Will assume transactional DDL.
INFO  \[alembic.context\] Running upgrade None -> 1975ea83b712

Wow that rocked! Note that the information we see on the screen is the result of the logging configuration set up in `alembic.ini` - logging the `alembic` stream to the console (standard error, specifically).

The process which occurred here included that Alembic first checked if the database had a table called `alembic_version`, and if not, created it. It looks in this table for the current version, if any, and then calculates the path from this version to the version requested, in this case `head`, which is known to be `1975ea83b712`. It then invokes the `upgrade()` method in each file to get to the target revision.

#### Running our Second Migration

Let's do another one so we have some things to play with. We again create a revision file:

$ alembic revision -m "Add a column"
Generating /path/to/yourapp/alembic/versions/ae1027a6acf\_add\_a\_column.py...
done

Let's edit this file and add a new column to the `account` table:

"""Add a column

Revision ID: ae1027a6acf
Revises: 1975ea83b712
Create Date: 2011-11-08 12:37:36.714947

"""

\# revision identifiers, used by Alembic.
revision \= 'ae1027a6acf'
down\_revision \= '1975ea83b712'

from alembic import op
import sqlalchemy as sa

def upgrade():
    op.add\_column('account', sa.Column('last\_transaction\_date', sa.DateTime))

def downgrade():
    op.drop\_column('account', 'last\_transaction\_date')

Running again to `head`:

$ alembic upgrade head
INFO  \[alembic.context\] Context class PostgresqlContext.
INFO  \[alembic.context\] Will assume transactional DDL.
INFO  \[alembic.context\] Running upgrade 1975ea83b712 -> ae1027a6acf

We've now added the `last_transaction_date` column to the database.

#### Partial Revision Identifiers

Any time we need to refer to a revision number explicitly, we have the option to use a partial number. As long as this number uniquely identifies the version, it may be used in any command in any place that version numbers are accepted:

$ alembic upgrade ae1

Above, we use `ae1` to refer to revision `ae1027a6acf`. Alembic will stop and let you know if more than one version starts with that prefix.

#### Relative Migration Identifiers

Relative upgrades/downgrades are also supported. To move two versions from the current, a decimal value "+N" can be supplied:

$ alembic upgrade +2

Negative values are accepted for downgrades:

$ alembic downgrade -1

Relative identifiers may also be in terms of a specific revision. For example, to upgrade to revision `ae1027a6acf` plus two additional steps:

$ alembic upgrade ae10+2

#### Getting Information

With a few revisions present we can get some information about the state of things.

First we can view the current revision:

$ alembic current
INFO  \[alembic.context\] Context class PostgresqlContext.
INFO  \[alembic.context\] Will assume transactional DDL.
Current revision for postgresql://scott:XXXXX@localhost/test: 1975ea83b712 -> ae1027a6acf (head), Add a column

`head` is displayed only if the revision identifier for this database matches the head revision.

We can also view history with `alembic history`; the `--verbose` option (accepted by several commands, including `history`, `current`, `heads` and `branches`) will show us full information about each revision:

$ alembic history --verbose

Rev: ae1027a6acf (head)
Parent: 1975ea83b712
Path: /path/to/yourproject/alembic/versions/ae1027a6acf\_add\_a\_column.py

    add a column

    Revision ID: ae1027a6acf
    Revises: 1975ea83b712
    Create Date: 2014-11-20 13:02:54.849677

Rev: 1975ea83b712
Parent: <base>
Path: /path/to/yourproject/alembic/versions/1975ea83b712\_add\_account\_table.py

    create account table

    Revision ID: 1975ea83b712
    Revises:
    Create Date: 2014-11-20 13:02:46.257104

##### Viewing History Ranges

Using the `-r` option to `alembic history`, we can also view various slices of history. The `-r` argument accepts an argument `[start]:[end]`, where either may be a revision number, symbols like `head`, `heads` or `base`, `current` to specify the current revision(s), as well as negative relative ranges for `[start]` and positive relative ranges for `[end]`:

$ alembic history -r1975ea:ae1027

A relative range starting from three revs ago up to current migration, which will invoke the migration environment against the database to get the current migration:

$ alembic history -r-3:current

Note

As illustrated above, to use ranges that start with a negative number (i.e. a dash), due to a [bug in argparse](https://github.com/python/cpython/issues/53580) , either the syntax `-r-<base>:<head>`, without any space, must be used as above:

$ alembic history -r-3:current

or if using `--rev-range`, an equals sign must be used:

$ alembic history --rev-range=-3:current

Using quotes or escape symbols will not work if there's a space after the argument name.

View all revisions from 1975 to the head:

$ alembic history -r1975ea:

#### Downgrading

We can illustrate a downgrade back to nothing, by calling `alembic downgrade` back to the beginning, which in Alembic is called `base`:

$ alembic downgrade base
INFO  \[alembic.context\] Context class PostgresqlContext.
INFO  \[alembic.context\] Will assume transactional DDL.
INFO  \[alembic.context\] Running downgrade ae1027a6acf -> 1975ea83b712
INFO  \[alembic.context\] Running downgrade 1975ea83b712 -> None

Back to nothing - and up again:

$ alembic upgrade head
INFO  \[alembic.context\] Context class PostgresqlContext.
INFO  \[alembic.context\] Will assume transactional DDL.
INFO  \[alembic.context\] Running upgrade None -> 1975ea83b712
INFO  \[alembic.context\] Running upgrade 1975ea83b712 -> ae1027a6acf

#### Next Steps

The vast majority of Alembic environments make heavy use of the "autogenerate" feature. Continue onto the next section, [Auto Generating Migrations](autogenerate.html).

---

## Auto Generating Migrations - Alembic 1.16.5 documentation

### Contents

-   [What does Autogenerate Detect (and what does it *not* detect?)](#what-does-autogenerate-detect-and-what-does-it-not-detect)
    -   [Notable 3-rd party libraries that extend the built-in Alembic autogenerate functionality](#notable-3-rd-party-libraries-that-extend-the-built-in-alembic-autogenerate-functionality)
-   [Autogenerating Multiple MetaData collections](#autogenerating-multiple-metadata-collections)
-   [Controlling What to be Autogenerated](#controlling-what-to-be-autogenerated)
    -   [Omitting Schema Names from the Autogenerate Process](#omitting-schema-names-from-the-autogenerate-process)
    -   [Omitting Table Names from the Autogenerate Process](#omitting-table-names-from-the-autogenerate-process)
    -   [Omitting Based on Object](#omitting-based-on-object)
-   [Comparing and Rendering Types](#comparing-and-rendering-types)
    -   [Controlling the Module Prefix](#controlling-the-module-prefix)
    -   [Affecting the Rendering of Types Themselves](#affecting-the-rendering-of-types-themselves)
    -   [Comparing Types](#comparing-types)
-   [Applying Post Processing and Python Code Formatters to Generated Revisions](#applying-post-processing-and-python-code-formatters-to-generated-revisions)
    -   [Basic Post Processor Configuration](#basic-post-processor-configuration)
    -   [Writing Custom Hooks as Python Functions](#writing-custom-hooks-as-python-functions)
-   [Running Alembic Check to test for new upgrade operations](#running-alembic-check-to-test-for-new-upgrade-operations)

### Auto Generating Migrations

Alembic can view the status of the database (pointed to by `sqlalchemy.url` in your `alembic.ini` file using the *current* schema) and compare against the table metadata in the application (your ORM which defines the *proposed* schema), generating the "obvious" migrations based on a comparison. This is achieved using the `--autogenerate` option to the `alembic revision` command, which places so-called *candidate* migrations into our new migrations file. We review and modify these by hand as needed, then proceed normally.

To use autogenerate, we first need to modify our `env.py` so that it gets access to a table metadata object that contains the target. Suppose our application has a [declarative base](https://docs.sqlalchemy.org/en/20/orm/extensions/declarative/index.html#declarative-toplevel "(in SQLAlchemy v2.0)") in `myapp.mymodel`. This base contains a [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") object which contains [`Table`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.Table "(in SQLAlchemy v2.0)") objects defining our database. We make sure this is loaded in `env.py` and then passed to [`EnvironmentContext.configure()`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure "alembic.runtime.environment.EnvironmentContext.configure") via the `target_metadata` argument. The `env.py` sample script used in the generic template already has a variable declaration near the top for our convenience, where we replace `None` with our [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)"). Starting with:

\# add your model's MetaData object here
\# for 'autogenerate' support
\# from myapp import mymodel
\# target\_metadata = mymodel.Base.metadata
target\_metadata \= None

we change to:

from myapp.mymodel import Base
target\_metadata \= Base.metadata

Note

The above example refers to the **generic alembic env.py template**, e.g. the one created by default when calling upon `alembic init`, and not the special-use templates such as `multidb`. Please consult the source code and comments within the `env.py` script directly for specific guidance on where and how the autogenerate metadata is established.

If we look later in the script, down in `run_migrations_online()`, we can see the directive passed to [`EnvironmentContext.configure()`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure "alembic.runtime.environment.EnvironmentContext.configure"):

def run\_migrations\_online():
    engine \= engine\_from\_config(
                config.get\_section(config.config\_ini\_section), prefix\='sqlalchemy.')

    with engine.connect() as connection:
        context.configure(
                    connection\=connection,
                    target\_metadata\=target\_metadata
                    )

        with context.begin\_transaction():
            context.run\_migrations()

We can then use the `alembic revision` command in conjunction with the `--autogenerate` option. Suppose our [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") contained a definition for the `account` table, and the database did not. We'd get output like:

$ alembic revision --autogenerate -m "Added account table"
INFO [alembic.context] Detected added table 'account'
Generating /path/to/foo/alembic/versions/27c6a30d7c24.py...done

We can then view our file `27c6a30d7c24.py` and see that a rudimentary migration is already present:

"""empty message

Revision ID: 27c6a30d7c24
Revises: None
Create Date: 2011-11-08 11:40:27.089406

"""

\# revision identifiers, used by Alembic.
revision \= '27c6a30d7c24'
down\_revision \= None

from alembic import op
import sqlalchemy as sa

def upgrade():
    \### commands auto generated by Alembic - please adjust! ###
    op.create\_table(
    'account',
    sa.Column('id', sa.Integer()),
    sa.Column('name', sa.String(length\=50), nullable\=False),
    sa.Column('description', sa.VARCHAR(200)),
    sa.Column('last\_transaction\_date', sa.DateTime()),
    sa.PrimaryKeyConstraint('id')
    )
    \### end Alembic commands ###

def downgrade():
    \### commands auto generated by Alembic - please adjust! ###
    op.drop\_table("account")
    \### end Alembic commands ###

The migration hasn't actually run yet, of course. We do that via the usual `upgrade` command. We should also go into our migration file and alter it as needed, including adjustments to the directives as well as the addition of other directives which these may be dependent on - specifically data changes in between creates/alters/drops.

#### What does Autogenerate Detect (and what does it *not* detect?)

The vast majority of user issues with Alembic centers on the topic of what kinds of changes autogenerate can and cannot detect reliably, as well as how it renders Python code for what it does detect. It is critical to note that **autogenerate is not intended to be perfect**. It is *always* necessary to manually review and correct the **candidate migrations** that autogenerate produces. The feature is getting more and more comprehensive and error-free as releases continue, but one should take note of the current limitations.

Autogenerate **will detect**:

-   Table additions, removals.
    
-   Column additions, removals.
    
-   Change of nullable status on columns.
    
-   Basic changes in indexes and explicitly-named unique constraints
    
-   Basic changes in foreign key constraints
    

Autogenerate can **optionally detect**:

-   Change of column type. This will occur by default unless the parameter [`EnvironmentContext.configure.compare_type`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.compare_type "alembic.runtime.environment.EnvironmentContext.configure") is set to `False`. The default implementation will reliably detect major changes, such as between `Numeric` and `String`, as well as accommodate for the types generated by SQLAlchemy's "generic" types such as `Boolean`. Arguments that are shared between both types, such as length and precision values, will also be compared. If either the metadata type or database type has **additional** arguments beyond that of the other type, these are **not** compared, such as if one numeric type featured a "scale" and other type did not, this would be seen as the backing database not supporting the value, or reporting on a default that the metadata did not specify.
    
    The type comparison logic is fully extensible as well; see [Comparing Types](#compare-types) for details.
    
-   Change of server default. This will occur if you set the [`EnvironmentContext.configure.compare_server_default`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.compare_server_default "alembic.runtime.environment.EnvironmentContext.configure") parameter to `True`, or to a custom callable function. This feature works well for simple cases but cannot always produce accurate results. The Postgresql backend will actually invoke the "detected" and "metadata" values against the database to determine equivalence. The feature is off by default so that it can be tested on the target schema first. Like type comparison, it can also be customized by passing a callable; see the function's documentation for details.
    

Autogenerate **can not detect**:

-   Changes of table name. These will come out as an add/drop of two different tables, and should be hand-edited into a name change instead.
    
-   Changes of column name. Like table name changes, these are detected as a column add/drop pair, which is not at all the same as a name change.
    
-   Anonymously named constraints. Give your constraints a name, e.g. `UniqueConstraint('col1', 'col2', name="my_name")`. See the section [The Importance of Naming Constraints](naming.html) for background on how to configure automatic naming schemes for constraints.
    
-   Special SQLAlchemy types such as [`Enum`](https://docs.sqlalchemy.org/en/20/core/type_basics.html#sqlalchemy.types.Enum "(in SQLAlchemy v2.0)") when generated on a backend which doesn't support ENUM directly - this because the representation of such a type in the non-supporting database, i.e. a CHAR+ CHECK constraint, could be any kind of CHAR+CHECK. For SQLAlchemy to determine that this is actually an ENUM would only be a guess, something that's generally a bad idea. To implement your own "guessing" function here, use the [`sqlalchemy.events.DDLEvents.column_reflect()`](https://docs.sqlalchemy.org/en/20/core/events.html#sqlalchemy.events.DDLEvents.column_reflect "(in SQLAlchemy v2.0)") event to detect when a CHAR (or whatever the target type is) is reflected, and change it to an ENUM (or whatever type is desired) if it is known that that's the intent of the type. The [`sqlalchemy.events.DDLEvents.after_parent_attach()`](https://docs.sqlalchemy.org/en/20/core/events.html#sqlalchemy.events.DDLEvents.after_parent_attach "(in SQLAlchemy v2.0)") can be used within the autogenerate process to intercept and un-attach unwanted CHECK constraints.
    

Autogenerate can't currently, but **will eventually detect**:

-   Some free-standing constraint additions and removals may not be supported, including PRIMARY KEY, EXCLUDE, CHECK; these are not necessarily implemented within the autogenerate detection system and also may not be supported by the supporting SQLAlchemy dialect.
    
-   Sequence additions, removals - not yet implemented.
    

##### Notable 3-rd party libraries that extend the built-in Alembic autogenerate functionality

-   [alembic-utils](https://github.com/olirice/alembic_utils) A library that adds autogenerate support PostgreSQL functions, views, triggers, etc.
    
-   [alembic-postgresql-enum](https://pypi.org/project/alembic-postgresql-enum) A library that adds autogenerate support for creation, alteration and deletion of Enums in PostgreSQL.
    

#### Autogenerating Multiple MetaData collections

The `target_metadata` collection may also be defined as a sequence if an application has multiple [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") collections involved:

from myapp.mymodel1 import Model1Base
from myapp.mymodel2 import Model2Base
target\_metadata \= \[Model1Base.metadata, Model2Base.metadata\]

The sequence of [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") collections will be consulted in order during the autogenerate process. Note that each [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") must contain **unique** table keys (e.g. the "key" is the combination of the table's name and schema); if two [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") objects contain a table with the same schema/name combination, an error is raised.

#### Controlling What to be Autogenerated

The autogenerate process scans across all table objects within the database that is referred towards by the current database connection in use.

The list of objects that are scanned in the target database connection include:

-   The "default" schema currently referred towards by the database connection.
    
-   If the [`EnvironmentContext.configure.include_schemas`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_schemas "alembic.runtime.environment.EnvironmentContext.configure") is set to `True`, all non-default "schemas", which are those names returned by the [`get_schema_names()`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector.get_schema_names "(in SQLAlchemy v2.0)") method of [`Inspector`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector "(in SQLAlchemy v2.0)"). The SQLAlchemy document [Specifying the Schema Name](https://docs.sqlalchemy.org/en/20/core/metadata.html#schema-table-schema-name "(in SQLAlchemy v2.0)") discusses the concept of a "schema" in detail.
    
-   Within each "schema", all tables present are scanned using the [`get_table_names()`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector.get_table_names "(in SQLAlchemy v2.0)") method of [`Inspector`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector "(in SQLAlchemy v2.0)").
    
-   Within each "table", most sub-objects of the each [`Table`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.Table "(in SQLAlchemy v2.0)") construct are scanned, including columns and some forms of constraints. This process ultimately involves the use of methods on [`Inspector`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector "(in SQLAlchemy v2.0)") including [`get_columns()`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector.get_columns "(in SQLAlchemy v2.0)"), [`get_indexes()`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector.get_indexes "(in SQLAlchemy v2.0)"), [`get_unique_constraints()`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector.get_unique_constraints "(in SQLAlchemy v2.0)"), [`get_foreign_keys()`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector.get_foreign_keys "(in SQLAlchemy v2.0)") (as of this writing, CHECK constraints and primary key constraints are not yet included).
    

See also

[Specifying the Schema Name](https://docs.sqlalchemy.org/en/20/core/metadata.html#schema-table-schema-name "(in SQLAlchemy v2.0)") - in depth introduction to how SQLAlchemy interprets schema names

[Remote-Schema Table Introspection and PostgreSQL search\_path](https://docs.sqlalchemy.org/en/20/dialects/postgresql.html#postgresql-schema-reflection "(in SQLAlchemy v2.0)") - important notes specific to the PostgreSQL database

##### Omitting Schema Names from the Autogenerate Process

As the above set of database objects are typically to be compared to the contents of a single [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") object, particularly when the [`EnvironmentContext.configure.include_schemas`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_schemas "alembic.runtime.environment.EnvironmentContext.configure") flag is enabled there is an important need to filter out unwanted "schemas", which for some database backends might be the list of all the databases present. This filtering is best performed using the [`EnvironmentContext.configure.include_name`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_name "alembic.runtime.environment.EnvironmentContext.configure") hook, which provides for a callable that may return a boolean true/false indicating if a particular schema name should be included:

def include\_name(name, type\_, parent\_names):
    if type\_ \== "schema":
        \# note this will not include the default schema
        return name in \["schema\_one", "schema\_two"\]
    else:
        return True

context.configure(
    \# ...
    include\_schemas \= True,
    include\_name \= include\_name
)

Above, when the list of schema names is first retrieved, the names will be filtered through the above `include_name` function so that only schemas named `"schema_one"` and `"schema_two"` will be considered by the autogenerate process.

In order to include **the default schema**, that is, the schema that is referred towards by the database connection **without** any explicit schema being specified, the name passed to the hook is `None`. To alter our above example to also include the default schema, we compare to `None` as well:

def include\_name(name, type\_, parent\_names):
    if type\_ \== "schema":
        \# this \*\*will\* include the default schema
        return name in \[None, "schema\_one", "schema\_two"\]
    else:
        return True

context.configure(
    \# ...
    include\_schemas \= True,
    include\_name \= include\_name
)

##### Omitting Table Names from the Autogenerate Process

The [`EnvironmentContext.configure.include_name`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_name "alembic.runtime.environment.EnvironmentContext.configure") hook is also most appropriate to limit the names of tables in the target database to be considered. If a target database has many tables that are not part of the [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)"), the autogenerate process will normally assume these are extraneous tables in the database to be dropped, and it will generate a [`Operations.drop_table()`](ops.html#alembic.operations.Operations.drop_table "alembic.operations.Operations.drop_table") operation for each. To prevent this, the [`EnvironmentContext.configure.include_name`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_name "alembic.runtime.environment.EnvironmentContext.configure") hook may be used to search for each name within the [`tables`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData.tables "(in SQLAlchemy v2.0)") collection of the [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") object and ensure names which aren't present are not included:

target\_metadata \= MyModel.metadata

def include\_name(name, type\_, parent\_names):
    if type\_ \== "table":
        return name in target\_metadata.tables
    else:
        return True

context.configure(
    \# ...
    target\_metadata \= target\_metadata,
    include\_name \= include\_name,
    include\_schemas \= False
)

The above example is limited to table names present in the default schema only. In order to search within a [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") collection for schema-qualified table names as well, a table present in the non default schema will be present under a name of the form `<schemaname>.<tablename>`. The [`EnvironmentContext.configure.include_name`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_name "alembic.runtime.environment.EnvironmentContext.configure") hook will present this schema name on a per-tablename basis in the `parent_names` dictionary, using the key `"schema_name"` that refers to the name of the schema currently being considered, or `None` if the schema is the default schema of the database connection:

\# example fragment

if parent\_names\["schema\_name"\] is None:
    return name in target\_metadata.tables
else:
    \# build out schema-qualified name explicitly...
    return (
        "%s.%s" % (parent\_names\["schema\_name"\], name) in
        target\_metadata.tables
    )

However more simply, the `parent_names` dictionary will also include the dot-concatenated name already constructed under the key `"schema_qualified_table_name"`, which will also be suitably formatted for tables in the default schema as well with the dot omitted. So the full example of omitting tables with schema support may look like:

target\_metadata \= MyModel.metadata

def include\_name(name, type\_, parent\_names):
    if type\_ \== "schema":
        return name in \[None, "schema\_one", "schema\_two"\]
    elif type\_ \== "table":
        \# use schema\_qualified\_table\_name directly
        return (
            parent\_names\["schema\_qualified\_table\_name"\] in
            target\_metadata.tables
        )
    else:
        return True

context.configure(
    \# ...
    target\_metadata \= target\_metadata,
    include\_name \= include\_name,
    include\_schemas \= True
)

The `parent_names` dictionary will also include the key `"table_name"` when the name being considered is that of a column or constraint object local to a particular table.

The [`EnvironmentContext.configure.include_name`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_name "alembic.runtime.environment.EnvironmentContext.configure") hook only refers to **reflected** objects, and not those located within the target [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") collection. For more fine-grained rules that include both [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") and reflected object, the [`EnvironmentContext.configure.include_object`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_object "alembic.runtime.environment.EnvironmentContext.configure") hook discussed in the next section is more appropriate.

##### Omitting Based on Object

The [`EnvironmentContext.configure.include_object`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.include_object "alembic.runtime.environment.EnvironmentContext.configure") hook provides for object-level inclusion/exclusion rules based on the [`Table`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.Table "(in SQLAlchemy v2.0)") object being reflected as well as the elements within it. This hook can be used to limit objects both from the local [`MetaData`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.MetaData "(in SQLAlchemy v2.0)") collection as well as from the target database. The limitation is that when it reports on objects in the database, it will have fully reflected that object, which can be expensive if a large number of objects will be omitted. The example below refers to a fine-grained rule that will skip changes on [`Column`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.Column "(in SQLAlchemy v2.0)") objects that have a user-defined flag `skip_autogenerate` placed into the [`info`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.Column.info "(in SQLAlchemy v2.0)") dictionary:

def include\_object(object, name, type\_, reflected, compare\_to):
    if (type\_ \== "column" and
        not reflected and
        object.info.get("skip\_autogenerate", False)):
        return False
    else:
        return True

context.configure(
    \# ...
    include\_object \= include\_object
)

#### Comparing and Rendering Types

The area of autogenerate's behavior of comparing and rendering Python-based type objects in migration scripts presents a challenge, in that there's a very wide variety of types to be rendered in scripts, including those part of SQLAlchemy as well as user-defined types. A few options are given to help out with this task.

##### Controlling the Module Prefix

When types are rendered, they are generated with a **module prefix**, so that they are available based on a relatively small number of imports. The rules for what the prefix is is based on the kind of datatype as well as configurational settings. For example, when Alembic renders SQLAlchemy types, it will by default prefix the type name with the prefix `sa.`:

Column("my\_column", sa.Integer())

The use of the `sa.` prefix is controllable by altering the value of [`EnvironmentContext.configure.sqlalchemy_module_prefix`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.sqlalchemy_module_prefix "alembic.runtime.environment.EnvironmentContext.configure"):

def run\_migrations\_online():
    \# ...

    context.configure(
                connection\=connection,
                target\_metadata\=target\_metadata,
                sqlalchemy\_module\_prefix\="sqla.",
                \# ...
                )

    \# ...

In either case, the `sa.` prefix, or whatever prefix is desired, should also be included in the imports section of `script.py.mako`; it also defaults to `import sqlalchemy as sa`.

For user-defined types, that is, any custom type that is not within the `sqlalchemy.` module namespace, by default Alembic will use the **value of \_\_module\_\_ for the custom type**:

Column("my\_column", myapp.models.utils.types.MyCustomType())

The imports for the above type again must be made present within the migration, either manually, or by adding it to `script.py.mako`.

The above custom type has a long and cumbersome name based on the use of `__module__` directly, which also implies that lots of imports would be needed in order to accommodate lots of types. For this reason, it is recommended that user-defined types used in migration scripts be made available from a single module. Suppose we call it `myapp.migration_types`:

\# myapp/migration\_types.py

from myapp.models.utils.types import MyCustomType

We can first add an import for `migration_types` to our `script.py.mako`:

from alembic import op
import sqlalchemy as sa
import myapp.migration\_types
${imports if imports else ""}

We then override Alembic's use of `__module__` by providing a fixed prefix, using the [`EnvironmentContext.configure.user_module_prefix`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.user_module_prefix "alembic.runtime.environment.EnvironmentContext.configure") option:

def run\_migrations\_online():
    \# ...

    context.configure(
                connection\=connection,
                target\_metadata\=target\_metadata,
                user\_module\_prefix\="myapp.migration\_types.",
                \# ...
                )

    \# ...

Above, we now would get a migration like:

Column("my\_column", myapp.migration\_types.MyCustomType())

Now, when we inevitably refactor our application to move `MyCustomType` somewhere else, we only need modify the `myapp.migration_types` module, instead of searching and replacing all instances within our migration scripts.

##### Affecting the Rendering of Types Themselves

The methodology Alembic uses to generate SQLAlchemy and user-defined type constructs as Python code is plain old `__repr__()`. SQLAlchemy's built-in types for the most part have a `__repr__()` that faithfully renders a Python-compatible constructor call, but there are some exceptions, particularly in those cases when a constructor accepts arguments that aren't compatible with `__repr__()`, such as a pickling function.

When building a custom type that will be rendered into a migration script, it is often necessary to explicitly give the type a `__repr__()` that will faithfully reproduce the constructor for that type. This, in combination with [`EnvironmentContext.configure.user_module_prefix`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.user_module_prefix "alembic.runtime.environment.EnvironmentContext.configure"), is usually enough. However, if additional behaviors are needed, a more comprehensive hook is the [`EnvironmentContext.configure.render_item`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.render_item "alembic.runtime.environment.EnvironmentContext.configure") option. This hook allows one to provide a callable function within `env.py` that will fully take over how a type is rendered, including its module prefix:

def render\_item(type\_, obj, autogen\_context):
    """Apply custom rendering for selected items."""

    if type\_ \== 'type' and isinstance(obj, MySpecialType):
        return "mypackage.%r" % obj

    \# default rendering for other objects
    return False

def run\_migrations\_online():
    \# ...

    context.configure(
                connection\=connection,
                target\_metadata\=target\_metadata,
                render\_item\=render\_item,
                \# ...
                )

    \# ...

In the above example, we'd ensure our `MySpecialType` includes an appropriate `__repr__()` method, which is invoked when we call it against `"%r"`.

The callable we use for [`EnvironmentContext.configure.render_item`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.render_item "alembic.runtime.environment.EnvironmentContext.configure") can also add imports to our migration script. The [`AutogenContext`](api/autogenerate.html#alembic.autogenerate.api.AutogenContext "alembic.autogenerate.api.AutogenContext") passed in contains a datamember called [`AutogenContext.imports`](api/autogenerate.html#alembic.autogenerate.api.AutogenContext.imports "alembic.autogenerate.api.AutogenContext.imports"), which is a Python `set()` for which we can add new imports. For example, if `MySpecialType` were in a module called `mymodel.types`, we can add the import for it as we encounter the type:

def render\_item(type\_, obj, autogen\_context):
    """Apply custom rendering for selected items."""

    if type\_ \== 'type' and isinstance(obj, MySpecialType):
        \# add import for this type
        autogen\_context.imports.add("from mymodel import types")
        return "types.%r" % obj

    \# default rendering for other objects
    return False

The finished migration script will include our imports where the `${imports}` expression is used, producing output such as:

from alembic import op
import sqlalchemy as sa
from mymodel import types

def upgrade():
    op.add\_column('sometable', Column('mycolumn', types.MySpecialType()))

##### Comparing Types

The default type comparison logic will work for SQLAlchemy built in types as well as basic user defined types. This logic is enabled by default. It can be disabled by setting the [`EnvironmentContext.configure.compare_type`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.compare_type "alembic.runtime.environment.EnvironmentContext.configure") to `False`:

context.configure(
    \# ...
    compare\_type \= False
)

Changed in version 1.12.0: The default value of [`EnvironmentContext.configure.compare_type`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.compare_type "alembic.runtime.environment.EnvironmentContext.configure") has been changed to `True`.

Note

The default type comparison logic (which is end-user extensible) currently (as of Alembic version 1.4.0) works by comparing the generated SQL for a column. It does this in two steps-

-   First, it compares the outer type of each column such as `VARCHAR` or `TEXT`. Dialect implementations can have synonyms that are considered equivalent, this is because some databases support types by converting them to another type. For example, NUMERIC and DECIMAL are considered equivalent on all backends, while on the Oracle backend the additional synonyms BIGINT, INTEGER, NUMBER, SMALLINT are added to this list of equivalents
    
-   Next, the arguments within the type, such as the lengths of strings, precision values for numerics, the elements inside of an enumeration are compared. If BOTH columns have arguments AND they are different, a change will be detected. If one column is just set to the default and the other has arguments, Alembic will pass on attempting to compare these. The rationale is that it is difficult to detect what a database backend sets as a default value without generating false positives.
    

Alternatively, the [`EnvironmentContext.configure.compare_type`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.compare_type "alembic.runtime.environment.EnvironmentContext.configure") parameter accepts a callable function which may be used to implement custom type comparison logic, for cases such as where special user defined types are being used:

def my\_compare\_type(context, inspected\_column,
            metadata\_column, inspected\_type, metadata\_type):
    \# return False if the metadata\_type is the same as the inspected\_type
    \# or None to allow the default implementation to compare these
    \# types. a return value of True means the two types do not
    \# match and should result in a type change operation.
    return None

context.configure(
    \# ...
    compare\_type \= my\_compare\_type
)

Above, `inspected_column` is a [`sqlalchemy.schema.Column`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.Column "(in SQLAlchemy v2.0)") as returned by [`sqlalchemy.engine.reflection.Inspector.reflect_table()`](https://docs.sqlalchemy.org/en/20/core/reflection.html#sqlalchemy.engine.reflection.Inspector.reflect_table "(in SQLAlchemy v2.0)"), whereas `metadata_column` is a [`sqlalchemy.schema.Column`](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.Column "(in SQLAlchemy v2.0)") from the local model environment. A return value of `None` indicates that default type comparison to proceed.

#### Applying Post Processing and Python Code Formatters to Generated Revisions

Revision scripts generated by the `alembic revision` command can optionally be piped through a series of post-production functions which may analyze or rewrite Python source code generated by Alembic, within the scope of running the `revision` command. The primary intended use of this feature is to run code-formatting tools such as [Black](https://black.readthedocs.io/) or [autopep8](https://pypi.org/project/autopep8/), as well as custom-written formatting and linter functions, on revision files as Alembic generates them. Any number of hooks can be configured and they will be run in series, given the path to the newly generated file as well as configuration options.

The post write hooks, when configured, run against generated revision files regardless of whether or not the autogenerate feature was used.

Note

Alembic's post write system is partially inspired by the [pre-commit](https://pre-commit.com/) tool, which configures git hooks that reformat source files as they are committed to a git repository. Pre-commit can serve this role for Alembic revision files as well, applying code formatters to them as they are committed. Alembic's post write hooks are useful only in that they can format the files immediately upon generation, rather than at commit time, and also can be useful for projects that prefer not to use pre-commit.

##### Basic Post Processor Configuration

The template samples for `alembic.ini` as well as `pyproject.toml` for applicable templates now include commented-out configuration illustrating how to configure code-formatting tools, or other tools like linters to run against the newly generated file path. Example from an alembic.ini file:

\[post\_write\_hooks\]

\# format using "black"
hooks\=black

black.type \= console\_scripts
black.entrypoint \= black
black.options \= \-l 79 REVISION\_SCRIPT\_FILENAME

The same example configured in a pyproject.toml file would look like:

\[\[tool.alembic.post\_write\_hooks\]\]

\# format using "black"
name \= "black"
type \= "console\_scripts"
entrypoint \= "black"
options \= "-l 79 REVISION\_SCRIPT\_FILENAME"

Above, we configure `hooks` to be a single post write hook labeled `"black"`. Note that this label is arbitrary. We then define the configuration for the `"black"` post write hook, which includes:

-   `type` - this is the type of hook we are running. Alembic includes three hook runners:
    
    -   `"console_scripts"`, which is specifically a Python function that uses `subprocess.run()` to invoke a separate Python script against the revision file;
        
    -   `"exec"`, which uses `subprocess.run()` to execute an arbitrary binary; and
        
    -   `"module"`, which uses `subprocess.run()` to invoke a Python module directly.
        
    
    For a custom-written hook function, this configuration variable would refer to the name under which the custom hook was registered; see the next section for an example.
    

Added in version 1.12: added new `exec` runner

Added in version 1.16.3: added new `module` runner

The following configuration option is specific to the `"console_scripts"` hook runner:

-   `entrypoint` - the name of the [setuptools entrypoint](https://setuptools.readthedocs.io/en/latest/pkg_resources.html#entry-points) that is used to define the console script. Within the scope of standard Python console scripts, this name will match the name of the shell command that is usually run for the code formatting tool, in this case `black`.
    

The following configuration option is specific to the `"exec"` hook runner:

-   `executable` - the name of the executable to invoke. Can be either a bare executable name which will be searched in `$PATH`, or a full pathname to avoid potential issues with path interception.
    

The following options are supported by both `"console_scripts"` and `"exec"`:

-   `options` - a line of command-line options that will be passed to the code formatting tool. In this case, we want to run the command `black /path/to/revision.py -l 79`. By default, the revision path is positioned as the first argument. In order specify a different position, we can use the `REVISION_SCRIPT_FILENAME` token as illustrated by the subsequent examples.
    
    Note
    
    Make sure options for the script are provided such that it will rewrite the input file **in place**. For example, when running `autopep8`, the `--in-place` option should be provided:
    
    \[post\_write\_hooks\]
    hooks \= autopep8
    autopep8.type \= console\_scripts
    autopep8.entrypoint \= autopep8
    autopep8.options \= \--in\-place REVISION\_SCRIPT\_FILENAME
    
-   `cwd` - optional working directory from which the code processing tool is run.
    

When running `alembic revision -m "rev1"`, we will now see the `black` tool's output as well:

$ alembic revision -m "rev1"
  Generating /path/to/project/versions/481b13bc369a\_rev1.py ... done
  Running post write hook "black" ...
reformatted /path/to/project/versions/481b13bc369a\_rev1.py
All done!   
1 file reformatted.
  done

Hooks may also be specified as a list of names, which correspond to hook runners that will run sequentially. As an example, we can also run the [zimports](https://pypi.org/project/zimports/) import rewriting tool (written by Alembic's author) subsequent to running the `black` tool. The alembic.ini configuration would be as follows:

\[post\_write\_hooks\]

\# format using "black", then "zimports"
hooks\=black, zimports

black.type \= console\_scripts
black.entrypoint \= black
black.options \= \-l 79 REVISION\_SCRIPT\_FILENAME

zimports.type \= console\_scripts
zimports.entrypoint \= zimports
zimports.options \= \--style google REVISION\_SCRIPT\_FILENAME

The equivalent pyproject.toml configuration would be:

\# format using "black", then "zimports"

\[\[tool.alembic.post\_write\_hooks\]\]
name \= "black"
type\="console\_scripts"
entrypoint \= "black"
options \= "-l 79 REVISION\_SCRIPT\_FILENAME"

\[\[tool.alembic.post\_write\_hooks\]\]
name \= "zimports"
type\="console\_scripts"
entrypoint \= "zimports"
options \= "--style google REVISION\_SCRIPT\_FILENAME"

When using the above configuration, a newly generated revision file will be processed first by the "black" tool, then by the "zimports" tool.

Alternatively, one can run pre-commit itself as follows:

\[post\_write\_hooks\]

hooks \= pre\-commit

pre\-commit.type \= console\_scripts
pre\-commit.entrypoint \= pre\-commit
pre\-commit.options \= run \--files REVISION\_SCRIPT\_FILENAME
pre\-commit.cwd \= %(here)s

(The last line helps to ensure that the `.pre-commit-config.yaml` file will always be found, regardless of from where the hook was called.)

##### Writing Custom Hooks as Python Functions

The previous section illustrated how to run command-line code formatters, through the use of a post write hook provided by Alembic known as `console_scripts`. This hook is in fact a Python function that is registered under that name using a registration function that may be used to register other types of hooks as well.

To illustrate, we will use the example of a short Python function that wants to rewrite the generated code to use tabs instead of four spaces. For simplicity, we will illustrate how this function can be present directly in the `env.py` file. The function is declared and registered using the [`write_hooks.register()`](api/script.html#alembic.script.write_hooks.register "alembic.script.write_hooks.register") decorator:

from alembic.script import write\_hooks
import re

@write\_hooks.register("spaces\_to\_tabs")
def convert\_spaces\_to\_tabs(filename, options):
    lines \= \[\]
    with open(filename) as file\_:
        for line in file\_:
            lines.append(
                re.sub(
                    r"^(    )+",
                    lambda m: "\\t" \* (len(m.group(1)) // 4),
                    line
                )
            )
    with open(filename, "w") as to\_write:
        to\_write.write("".join(lines))

Our new `"spaces_to_tabs"` hook can be configured in alembic.ini as follows:

\[alembic\]

\# ...

\# ensure the revision command loads env.py
revision\_environment \= true

\[post\_write\_hooks\]

hooks \= spaces\_to\_tabs

spaces\_to\_tabs.type \= spaces\_to\_tabs

When `alembic revision` is run, the `env.py` file will be loaded in all cases, the custom "spaces\_to_tabs" function will be registered and it will then be run against the newly generated file path:

$ alembic revision -m "rev1"
  Generating /path/to/project/versions/481b13bc369a\_rev1.py ... done
  Running post write hook "spaces\_to\_tabs" ...
  done

#### Running Alembic Check to test for new upgrade operations

When developing code it's useful to know if a set of code changes has made any net change to the database model, such that new revisions would need to be generated. To automate this, Alembic provides the `alembic check` command. This command will run through the same process as `alembic revision --autogenerate`, up until the point where revision files would be generated, however does not generate any new files. Instead, it returns an error code plus a message if it is detected that new operations would be rendered into a new revision, or if not, returns a success code plus a message. When `alembic check` returns a success code, this is an indication that the `alembic revision --autogenerate` command would produce only empty migrations, and does not need to be run.

`alembic check` can be worked into CI systems and on-commit schemes to ensure that incoming code does not warrant new revisions to be generated. In the example below, a check that detects new operations is illustrated:

$ alembic check
FAILED: New upgrade operations detected: \[
  ('add\_column', None, 'my\_table', Column('data', String(), table=<my\_table>)),
  ('add\_column', None, 'my\_table', Column('newcol', Integer(), table=<my\_table>))\]

by contrast, when no new operations are detected:

$ alembic check
No new upgrade operations detected.

Added in version 1.9.0.

Note

The `alembic check` command uses the same model comparison process as the `alembic revision --autogenerate` process. This means parameters such as [`EnvironmentContext.configure.compare_type`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.compare_type "alembic.runtime.environment.EnvironmentContext.configure") and [`EnvironmentContext.configure.compare_server_default`](api/runtime.html#alembic.runtime.environment.EnvironmentContext.configure.params.compare_server_default "alembic.runtime.environment.EnvironmentContext.configure") are in play as usual, as well as that limitations in autogenerate detection are the same when running `alembic check`.